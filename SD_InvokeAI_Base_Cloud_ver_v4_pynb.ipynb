{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geo-tp/Keras-Colaboratory-Models/blob/main/SD_InvokeAI_Base_Cloud_ver_v4_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqY-GmKTL8V"
      },
      "source": [
        "# **StableDiffusion InvokeAI Base Cloud version**\n",
        "\n",
        "\n",
        "![youtube.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAJ1BMVEVHcEz/AAD/AAD/AAD/AAD/AAD/AAD/AAD/AAD/////mJj/wcH/jY3aUCqcAAAACHRSTlMA8czbELSvDrGIfzkAAABCSURBVBiVY2AgA7CwMTMycgABIyMzGztQgIkDCTABBThQAEyAixtNgIeTkwu/AIYWZEMxrGVhZWaE8BiZWVnI8RoAJWEEDt2WmW4AAAAASUVORK5CYII=) **[YouTube](https://www.youtube.com/@marat_ai)** | ![youtube.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAA0lBMVEVHcEwASXEAVIIASXEAW40AW40AW40AW40AW40AW40ASXEARmwASXEAPV4ATnkAQGQAUoAAUn8AWowAQmYANFEANVIAQWUASXEAUHwAQmcAWowASXEAUX0AW40ASXGPscSPr8B/pLh/rcYMUXdJfZkDS3KlwtIqdqBWhqB9q8WZtsY/dpQzbY1Xh6GUs8MAWowAUHwAVoUqdp8AVIJ9pLkqZ4h9orelvsyJq70AWosAWYoATniNrb+kwM8ATHZ+oreBpbnF1t8DS3PI1+BbiaNbiqT25ex8AAAAHXRSTlMAmzOe3PvEmp3+3Ar+CjM0M/v7CgoKCsUzNNz7+yV3I4EAAACzSURBVBjTTY/XEoJADEUjbUEBezdrASxg7737/79kdmEcz9PeM5NsLgCRY5qua0yBmKJpocQyMyJXDPxhCGPiHyZAzcJBvy3pL9FSgCGOhlwyXC+QgYbYO/si+/suXzVAJ+Hdyfg3r8t5Kxbj12TyGAvRlCPR9Pl5B9OIRFouDQOxIwi3nKfApW8vHcluw+26POx45QkqXerQ6YdTnKtlUcahcrM5RVstJX1dphXy6VRWvL8EBRlO0i9n9wAAAABJRU5ErkJggg==) **[sdg.marat@gmail.com]** |\n",
        "![pp.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAtUlEQVQ4jWNgYGBYCcSrgLibARNwAnEUEE8G4gVAXAvEOuiK/gHxfyC+gCbuAMSPoXLIGKR+NhBz4DPACoh/YNGMjDcAMSM2A5iB+DoBzTAcgc0AByI1g/BebAYUkWDAe2wGlJFgwBdsBviTYMBpbAZwAfFLIg0owGYACEQRofk8AzQt4EpI2UD8C4fmk0AsBVOIywAQUGaAJPEjQHwJiNcBcTQDJK3AAT4DiAIDbwC+7EwQAADZX5HHysvpxQAAAABJRU5ErkJggg==) [Other Notebooks](https://www.patreon.com/marat_ai)\n",
        "\n",
        "_You don't need additional Google Drive storage because uploaded models are not stored on your Google Drive. After the session ends, all data will be deleted._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JQ5qVdNPFqYJ"
      },
      "outputs": [],
      "source": [
        "#@markdown # **STEP 1**\n",
        "#@markdown ## Requirements\n",
        "#@markdown It might finished with error but is not the error, just execute the next cell\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/rocketpal/InvokeAI\n",
        "!pip install -q dependency_injector diffusers einops eventlet facexlib flask_cors flask_socketio flaskwebgui getpass_asterisk huggingface-hub\n",
        "!pip install -q kornia omegaconf pudb pyreadline3 pytorch-lightning realesrgan streamlit taming-transformers-rom1504 test-tube torch-fidelity\n",
        "!pip install -q torchmetrics transformers picklescan\n",
        "!pip install -q pillow xformers==0.0.22 triton==2.0.0 -U\n",
        "clear_output()\n",
        "\n",
        "!pip install -q git+https://github.com/invoke-ai/GFPGAN@basicsr-1.4.2#egg=gfpgan\n",
        "!pip install -q git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install -q git+https://github.com/Birch-san/k-diffusion.git@mps#egg=k-diffusion\n",
        "!pip install -q git+https://github.com/invoke-ai/clipseg.git@relaxed-python-requirement#egg=clipseg\n",
        "!pip install -q git+https://github.com/invoke-ai/PyPatchMatch@0.1.4#egg=pypatchmatch\n",
        "%cd /content/InvokeAI/\n",
        "!pip install -q -e .\n",
        "clear_output()\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/rocketpal/InvokeAI-colab/main/INITIAL_MODELS.yaml -O /content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml\n",
        "clear_output()\n",
        "\n",
        "print('\u001b[1;32mDone!')\n",
        "\n",
        "!pip install python-socketio==5.9.0\n",
        "clear_output()\n",
        "\n",
        "#exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aBZ0AbI-U_zk",
        "outputId": "e3557c35-ffd5-48b1-d671-c0f80d6fc10f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **STEP 2**\n",
        "#@markdown ## Downloading models _(checkpoints, LoRAs, ControlNets, etc.)_\n",
        "#@markdown To configure the downloading of models, edit this file:\n",
        "#@markdown _/content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml_\n",
        "\n",
        "#@markdown P.S. It's fully explained in the tutorial.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-model-install.py --root_dir /content/db --yes\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AuFwU5t8POIS",
        "outputId": "853d8178-3958-456a-d772-b289e07a7289",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [1;32m Model just loaded! ðŸš€\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### Load Model (option2)\n",
        "model_link = \"https://civitai.com/api/download/models/128713?type=Model&format=SafeTensor&size=pruned&fp=fp16\" # @param {type:\"string\"}\n",
        "\n",
        "!wget -O /content/db/models/sd-1/main/model.safetensors \"{model_link}\"\n",
        "\n",
        "clear_output()\n",
        "print(' [1;32m Model just loaded! ðŸš€')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWoTrZLRP5zh",
        "outputId": "378225df-46c8-415e-c2a0-95c03c8cb8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/InvokeAI\n",
            "Warning: Permanently added 'remote.moe' (ED25519) to the list of known hosts.\n",
            "\u001b[1mhttp\u001b[0m (80)\n",
            "http://c6cnckciwy4gseqhxfjivpzmgh6uzfewdfqmjwf3t5ero4q6ljhq.remote.moe/\n",
            "\n",
            "$\n",
            " \n",
            "2023-12-17 21:45:01.664245: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-17 21:45:01.664291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-17 21:45:01.671242: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-17 21:45:03.586548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            ">> patchmatch.patch_match: INFO - Compiling and loading c extensions from \"/usr/local/lib/python3.10/dist-packages/patchmatch\".\n",
            ">> patchmatch.patch_match: WARNING - patchmatch failed to load or compile.\n",
            ">> patchmatch.patch_match: WARNING - Refer to https://github.com/invoke-ai/InvokeAI/blob/main/docs/installation/INSTALL_PATCHMATCH.md for installation instructions.\n",
            "\u001b[38;20m[2023-12-17 21:45:14,299]::[InvokeAI]::INFO --> Patchmatch not loaded (nonfatal)\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:15,801]::[uvicorn.error]::INFO --> Started server process [5274]\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:15,801]::[uvicorn.error]::INFO --> Waiting for application startup.\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:15,802]::[InvokeAI]::INFO --> InvokeAI version 3.1.0\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:15,803]::[InvokeAI]::INFO --> Root directory = /content/db\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:15,946]::[InvokeAI]::INFO --> GPU device = cuda Tesla T4\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:15,956]::[InvokeAI]::INFO --> Scanning /content/db/models for new models\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:16,795]::[InvokeAI]::INFO --> Scanned 6 files and directories, imported 0 models\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:16,799]::[InvokeAI]::INFO --> Model manager service initialized\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:16,848]::[uvicorn.error]::INFO --> Application startup complete.\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:16,848]::[uvicorn.error]::INFO --> Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:35,081]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET / HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:35,328]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /assets/index-08cda350.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:36,576]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /assets/favicon-0d253ced.ico HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:36,854]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /assets/ThemeLocaleProvider-707a230a.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:37,027]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /assets/menu-3d10c968.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:37,029]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /assets/ThemeLocaleProvider-90f0fcd3.css HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:37,264]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /locales/en.json HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:37,264]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /assets/logo-13003d72.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:37,616]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /assets/App-6125620a.css HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:37,617]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /assets/App-78495256.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:38,433]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /assets/inter-latin-wght-normal-450f3ba4.woff2 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:38,451]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /socket.io/?EIO=4&transport=polling&t=OnvlUas HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:38,606]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/app/version HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,039]::[InvokeAI]::INFO --> NSFW checker initialized\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,040]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/app/config HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,042]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/models/?model_type=embedding HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,043]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=main HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,044]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=onnx HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,045]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/models/?model_type=vae HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,046]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"POST /socket.io/?EIO=4&transport=polling&t=OnvlUe4&sid=8Tnd1oCXSGizBxWJAAAA HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,378]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/models/?model_type=controlnet HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,379]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /socket.io/?EIO=4&transport=polling&t=OnvlUe5&sid=8Tnd1oCXSGizBxWJAAAA HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,548]::[uvicorn.error]::INFO --> ('92.157.5.202', 0) - \"WebSocket /socket.io/?EIO=4&transport=websocket&sid=8Tnd1oCXSGizBxWJAAAA\" [accepted]\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,549]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/models/?model_type=lora HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,550]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/boards/?all=true HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,550]::[uvicorn.error]::INFO --> connection open\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,673]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,674]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:47,718]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /socket.io/?EIO=4&transport=polling&t=OnvlWq-&sid=8Tnd1oCXSGizBxWJAAAA HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:48,647]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /openapi.json HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:48,650]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=100&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:48,651]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=main HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:48,652]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/models/?model_type=vae HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:48,653]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/models/?model_type=embedding HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:48,655]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/app/config HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:49,519]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/app/version HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:45:49,520]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /socket.io/?EIO=4&transport=polling&t=OnvlWus&sid=8Tnd1oCXSGizBxWJAAAA HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:46:27,173]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:46:27,446]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"PUT /api/v1/sessions/bfb70cae-0e4f-4a3f-aa84-25cf2caf8f1a/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:46:27,526]::[InvokeAI]::INFO --> Converting /content/db/models/sd-1/main/model.safetensors to diffusers format\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:46:50,642]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:tokenizer\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:46:51,590]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:text_encoder\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:06,473]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:unet\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:11,171]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:scheduler\u001b[0m\n",
            "100% 50/50 [00:08<00:00,  5.70it/s]\n",
            "\u001b[38;20m[2023-12-17 21:47:21,279]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:vae\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,678]::[InvokeAI]::INFO --> Graph stats: bfb70cae-0e4f-4a3f-aa84-25cf2caf8f1a\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,679]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,679]::[InvokeAI]::INFO -->              main_model_loader     1     0.010s     0.000G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,679]::[InvokeAI]::INFO -->                      clip_skip     1     0.011s     0.000G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,679]::[InvokeAI]::INFO -->                         compel     2    38.833s     0.246G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,680]::[InvokeAI]::INFO -->                       rand_int     1     0.014s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,680]::[InvokeAI]::INFO -->                  range_of_size     1     0.009s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,680]::[InvokeAI]::INFO -->                        iterate     1     0.009s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,680]::[InvokeAI]::INFO -->                          noise     1     0.014s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,680]::[InvokeAI]::INFO -->                denoise_latents     1    14.765s     1.986G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,681]::[InvokeAI]::INFO -->           metadata_accumulator     1     0.011s     1.858G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,681]::[InvokeAI]::INFO -->                            l2i     1     5.396s     1.858G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,681]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   59.071s\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,681]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 6.47G (+1.709G)\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,682]::[InvokeAI]::INFO --> RAM used to load models: 1.99G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,682]::[InvokeAI]::INFO --> VRAM in use: 0.303G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,682]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,682]::[InvokeAI]::INFO -->    Model cache hits: 2\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,683]::[InvokeAI]::INFO -->    Model cache misses: 5\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,683]::[InvokeAI]::INFO -->    Models cached: 5\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,683]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:26,683]::[InvokeAI]::INFO -->    Cache high water mark: 1.99/6.00G\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:27,185]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/images/i/184e20e4-b07e-4beb-9ab1-5b2709e5864c.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:27,466]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/images/i/184e20e4-b07e-4beb-9ab1-5b2709e5864c.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:27,641]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/images/i/184e20e4-b07e-4beb-9ab1-5b2709e5864c.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:27,693]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:27,806]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:27,807]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/images/i/184e20e4-b07e-4beb-9ab1-5b2709e5864c.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-12-17 21:47:27,807]::[uvicorn.access]::INFO --> 92.157.5.202:0 - \"GET /api/v1/images/i/184e20e4-b07e-4beb-9ab1-5b2709e5864c.png/full HTTP/1.1\" 200\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **STEP 3**\n",
        "#@markdown ## Run StableDiffusion InvokeAI\n",
        "\n",
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "clear_output()\n",
        "\n",
        "\n",
        "id_rsa_file = \"/content/InvokeAI/id_rsa\"\n",
        "id_rsa_pub_file = \"/content/InvokeAI/id_rsa.pub\"\n",
        "if os.path.exists(id_rsa_file):\n",
        "    os.remove(id_rsa_file)\n",
        "if os.path.exists(id_rsa_pub_file):\n",
        "    os.remove(id_rsa_pub_file)\n",
        "clear_output()\n",
        "\n",
        "def gen_key(path: Union[str, Path]) -> None:\n",
        "    path = Path(path)\n",
        "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "    args = shlex.split(arg_string)\n",
        "    subprocess.run(args, check=True)\n",
        "    path.chmod(0o600)\n",
        "\n",
        "ssh_name = \"id_rsa\"\n",
        "ssh_path = Path(os.path.dirname(os.getcwd())) / ssh_name\n",
        "gen_key(ssh_path)\n",
        "clear_output()\n",
        "\n",
        "import threading\n",
        "def tunnel():\n",
        "  !ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i /content/id_rsa remote.moe\n",
        "threading.Thread(target=tunnel, daemon=True).start()\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-web.py --root /content/db"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}